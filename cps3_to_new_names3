import json
import boto3
import io
import pandas as pd
import s3fs
import fsspec
import csv
import urllib.parse
import re 
from datetime import date


#my file uploaded location is s3://nagesh2022/project_task1/

def lambda_handler(event, context):
    # TODO implement
    s3 = boto3.client('s3')

    bucket_name=event['Records'][0]['s3']['bucket']['name']
    oj=event['Records'][0]['s3']['object']['key']
    
    s3 = boto3.resource('s3')
    list_of_files=list(s3.Bucket(bucket_name).objects.filter(Prefix=oj))
    #print("l: ",list_of_files) l: [s3.ObjectSummary(bucket_name='nagesh2022', key='project_task1/resultjson.csv')]
    list_of_files.sort(key=lambda l:l.last_modified) 
    #print('f: ',list_of_files) f: [s3.ObjectSummary(bucket_name='nagesh2022', key='project_task1/resultjson.csv')]
    
    prefix_file_name=list_of_files[-1].key
    #print("file ",file_name) file project_task1/resultjson.csv
    
    prefix=prefix_file_name.split('/')[0:-1]  #project_task1
    file_name_ext=prefix_file_name.split('/')[-1]  # resultjson.json
    file_name=file_name_ext.split(".")[0]
    
    today=date.today()
    d1 = today.strftime("%d-%m-%Y")
    
    new_file_name=file_name+"_"+d1+file_name_ext.split(".")[-1]
    print(new_file_name) # resultjson_18-09-2022
    
    output_file_name='output/'+new_file_name
    print(output_file_name) # output/resultjson_18-09-2022
    
    input_location=bucket_name+'/'+oj
    print(input_location)
    
    #s3.copy_object(Bucket=bucket_name, CopySource=input_location, Key=output_file_name)
    
    s3.Object(bucket_name,output_file_name).copy_from(CopySource=input_location)
    
    #copy_source={ Bucket : bucket_name, key :prefix_file_name }
    
    #s3.meta.client.copy(copy_source,bucket_name, 'output/')
    
    print("job executed")
    
    return {
        'statusCode': 200,
        'body': json.dumps('Hello from Lambda!')
    }
